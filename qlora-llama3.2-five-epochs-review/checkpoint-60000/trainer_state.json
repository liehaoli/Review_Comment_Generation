{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0767793443179885,
  "eval_steps": 500,
  "global_step": 60000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06794632240529981,
      "grad_norm": 0.774989664554596,
      "learning_rate": 0.00019863173017719096,
      "loss": 1.5766,
      "step": 1000
    },
    {
      "epoch": 0.13589264481059962,
      "grad_norm": 0.6693995594978333,
      "learning_rate": 0.00019589519053157283,
      "loss": 1.415,
      "step": 2000
    },
    {
      "epoch": 0.20383896721589945,
      "grad_norm": 0.6657105684280396,
      "learning_rate": 0.00019315865088595472,
      "loss": 1.3991,
      "step": 3000
    },
    {
      "epoch": 0.27178528962119924,
      "grad_norm": 0.5814666152000427,
      "learning_rate": 0.0001904221112403366,
      "loss": 1.3772,
      "step": 4000
    },
    {
      "epoch": 0.33973161202649904,
      "grad_norm": 0.6364384889602661,
      "learning_rate": 0.0001876855715947185,
      "loss": 1.3715,
      "step": 5000
    },
    {
      "epoch": 0.4076779344317989,
      "grad_norm": 0.7800090312957764,
      "learning_rate": 0.00018494903194910038,
      "loss": 1.3492,
      "step": 6000
    },
    {
      "epoch": 0.4756242568370987,
      "grad_norm": 0.7139025330543518,
      "learning_rate": 0.00018221249230348225,
      "loss": 1.3515,
      "step": 7000
    },
    {
      "epoch": 0.5435705792423985,
      "grad_norm": 0.6076120138168335,
      "learning_rate": 0.00017947595265786415,
      "loss": 1.3424,
      "step": 8000
    },
    {
      "epoch": 0.6115169016476983,
      "grad_norm": 0.6763502359390259,
      "learning_rate": 0.00017673941301224602,
      "loss": 1.3496,
      "step": 9000
    },
    {
      "epoch": 0.6794632240529981,
      "grad_norm": 0.6849209070205688,
      "learning_rate": 0.0001740028733666279,
      "loss": 1.3256,
      "step": 10000
    },
    {
      "epoch": 0.7474095464582979,
      "grad_norm": 0.6600037813186646,
      "learning_rate": 0.0001712663337210098,
      "loss": 1.3251,
      "step": 11000
    },
    {
      "epoch": 0.8153558688635978,
      "grad_norm": 0.692144513130188,
      "learning_rate": 0.00016852979407539168,
      "loss": 1.322,
      "step": 12000
    },
    {
      "epoch": 0.8833021912688975,
      "grad_norm": 0.7356142401695251,
      "learning_rate": 0.00016579325442977357,
      "loss": 1.3186,
      "step": 13000
    },
    {
      "epoch": 0.9512485136741974,
      "grad_norm": 0.7606330513954163,
      "learning_rate": 0.00016305671478415544,
      "loss": 1.3165,
      "step": 14000
    },
    {
      "epoch": 1.0191948360794971,
      "grad_norm": 1.1813161373138428,
      "learning_rate": 0.0001603201751385373,
      "loss": 1.2796,
      "step": 15000
    },
    {
      "epoch": 1.087141158484797,
      "grad_norm": 0.7667589783668518,
      "learning_rate": 0.0001575836354929192,
      "loss": 1.216,
      "step": 16000
    },
    {
      "epoch": 1.1550874808900968,
      "grad_norm": 0.907273530960083,
      "learning_rate": 0.0001548470958473011,
      "loss": 1.2249,
      "step": 17000
    },
    {
      "epoch": 1.2230338032953967,
      "grad_norm": 1.0984625816345215,
      "learning_rate": 0.00015211055620168297,
      "loss": 1.2245,
      "step": 18000
    },
    {
      "epoch": 1.2909801257006963,
      "grad_norm": 0.9024593830108643,
      "learning_rate": 0.00014937401655606487,
      "loss": 1.2171,
      "step": 19000
    },
    {
      "epoch": 1.3589264481059962,
      "grad_norm": 0.7656705379486084,
      "learning_rate": 0.00014663747691044673,
      "loss": 1.2234,
      "step": 20000
    },
    {
      "epoch": 1.426872770511296,
      "grad_norm": 0.8527669310569763,
      "learning_rate": 0.00014390093726482863,
      "loss": 1.2229,
      "step": 21000
    },
    {
      "epoch": 1.4948190929165959,
      "grad_norm": 0.9236572980880737,
      "learning_rate": 0.00014116439761921053,
      "loss": 1.2215,
      "step": 22000
    },
    {
      "epoch": 1.5627654153218957,
      "grad_norm": 0.8176859021186829,
      "learning_rate": 0.0001384278579735924,
      "loss": 1.2165,
      "step": 23000
    },
    {
      "epoch": 1.6307117377271956,
      "grad_norm": 0.7690150141716003,
      "learning_rate": 0.0001356913183279743,
      "loss": 1.208,
      "step": 24000
    },
    {
      "epoch": 1.6986580601324954,
      "grad_norm": 0.9268544912338257,
      "learning_rate": 0.00013295477868235619,
      "loss": 1.2114,
      "step": 25000
    },
    {
      "epoch": 1.7666043825377953,
      "grad_norm": 0.8721513748168945,
      "learning_rate": 0.00013021823903673805,
      "loss": 1.2089,
      "step": 26000
    },
    {
      "epoch": 1.834550704943095,
      "grad_norm": 0.994766116142273,
      "learning_rate": 0.00012748169939111992,
      "loss": 1.2163,
      "step": 27000
    },
    {
      "epoch": 1.9024970273483948,
      "grad_norm": 0.8060365319252014,
      "learning_rate": 0.00012474515974550182,
      "loss": 1.2111,
      "step": 28000
    },
    {
      "epoch": 1.9704433497536946,
      "grad_norm": 1.0219383239746094,
      "learning_rate": 0.0001220086200998837,
      "loss": 1.2114,
      "step": 29000
    },
    {
      "epoch": 2.0383896721589942,
      "grad_norm": 0.8387779593467712,
      "learning_rate": 0.00011927208045426558,
      "loss": 1.1387,
      "step": 30000
    },
    {
      "epoch": 2.106335994564294,
      "grad_norm": 0.8910295367240906,
      "learning_rate": 0.00011653554080864748,
      "loss": 1.0939,
      "step": 31000
    },
    {
      "epoch": 2.174282316969594,
      "grad_norm": 0.8943020105361938,
      "learning_rate": 0.00011379900116302935,
      "loss": 1.1025,
      "step": 32000
    },
    {
      "epoch": 2.242228639374894,
      "grad_norm": 0.9503738284111023,
      "learning_rate": 0.00011106246151741124,
      "loss": 1.1136,
      "step": 33000
    },
    {
      "epoch": 2.3101749617801937,
      "grad_norm": 0.9346680641174316,
      "learning_rate": 0.00010832592187179311,
      "loss": 1.1055,
      "step": 34000
    },
    {
      "epoch": 2.3781212841854935,
      "grad_norm": 0.8477476835250854,
      "learning_rate": 0.00010558938222617501,
      "loss": 1.1118,
      "step": 35000
    },
    {
      "epoch": 2.4460676065907934,
      "grad_norm": 0.9326462745666504,
      "learning_rate": 0.00010285284258055689,
      "loss": 1.1075,
      "step": 36000
    },
    {
      "epoch": 2.514013928996093,
      "grad_norm": 0.9763316512107849,
      "learning_rate": 0.00010011630293493876,
      "loss": 1.111,
      "step": 37000
    },
    {
      "epoch": 2.5819602514013926,
      "grad_norm": 1.0852596759796143,
      "learning_rate": 9.737976328932066e-05,
      "loss": 1.1122,
      "step": 38000
    },
    {
      "epoch": 2.6499065738066925,
      "grad_norm": 0.9347143173217773,
      "learning_rate": 9.464322364370254e-05,
      "loss": 1.1169,
      "step": 39000
    },
    {
      "epoch": 2.7178528962119923,
      "grad_norm": 1.01417076587677,
      "learning_rate": 9.190668399808443e-05,
      "loss": 1.1134,
      "step": 40000
    },
    {
      "epoch": 2.785799218617292,
      "grad_norm": 0.7889823913574219,
      "learning_rate": 8.917014435246632e-05,
      "loss": 1.1112,
      "step": 41000
    },
    {
      "epoch": 2.853745541022592,
      "grad_norm": 1.070785403251648,
      "learning_rate": 8.64336047068482e-05,
      "loss": 1.1057,
      "step": 42000
    },
    {
      "epoch": 2.921691863427892,
      "grad_norm": 0.90571528673172,
      "learning_rate": 8.369706506123007e-05,
      "loss": 1.1005,
      "step": 43000
    },
    {
      "epoch": 2.9896381858331917,
      "grad_norm": 0.8425784111022949,
      "learning_rate": 8.096052541561196e-05,
      "loss": 1.1069,
      "step": 44000
    },
    {
      "epoch": 3.0575845082384916,
      "grad_norm": 0.8596636652946472,
      "learning_rate": 7.822398576999384e-05,
      "loss": 1.0108,
      "step": 45000
    },
    {
      "epoch": 3.1255308306437914,
      "grad_norm": 1.1015009880065918,
      "learning_rate": 7.548744612437573e-05,
      "loss": 0.9982,
      "step": 46000
    },
    {
      "epoch": 3.1934771530490913,
      "grad_norm": 1.1420307159423828,
      "learning_rate": 7.275090647875762e-05,
      "loss": 0.9971,
      "step": 47000
    },
    {
      "epoch": 3.261423475454391,
      "grad_norm": 1.037899136543274,
      "learning_rate": 7.00143668331395e-05,
      "loss": 1.0097,
      "step": 48000
    },
    {
      "epoch": 3.329369797859691,
      "grad_norm": 1.1541073322296143,
      "learning_rate": 6.727782718752139e-05,
      "loss": 0.9999,
      "step": 49000
    },
    {
      "epoch": 3.397316120264991,
      "grad_norm": 1.6435130834579468,
      "learning_rate": 6.454128754190326e-05,
      "loss": 1.0092,
      "step": 50000
    },
    {
      "epoch": 3.4652624426702907,
      "grad_norm": 1.1124908924102783,
      "learning_rate": 6.180474789628515e-05,
      "loss": 1.0015,
      "step": 51000
    },
    {
      "epoch": 3.53320876507559,
      "grad_norm": 1.079288363456726,
      "learning_rate": 5.9068208250667034e-05,
      "loss": 1.0111,
      "step": 52000
    },
    {
      "epoch": 3.60115508748089,
      "grad_norm": 1.134521722793579,
      "learning_rate": 5.6331668605048916e-05,
      "loss": 1.0057,
      "step": 53000
    },
    {
      "epoch": 3.66910140988619,
      "grad_norm": 1.0982341766357422,
      "learning_rate": 5.3595128959430805e-05,
      "loss": 1.0062,
      "step": 54000
    },
    {
      "epoch": 3.7370477322914897,
      "grad_norm": 1.366531491279602,
      "learning_rate": 5.085858931381269e-05,
      "loss": 1.0096,
      "step": 55000
    },
    {
      "epoch": 3.8049940546967895,
      "grad_norm": 1.064141035079956,
      "learning_rate": 4.812204966819457e-05,
      "loss": 1.0108,
      "step": 56000
    },
    {
      "epoch": 3.8729403771020894,
      "grad_norm": 0.8890607953071594,
      "learning_rate": 4.538551002257645e-05,
      "loss": 0.9952,
      "step": 57000
    },
    {
      "epoch": 3.9408866995073892,
      "grad_norm": 1.1224271059036255,
      "learning_rate": 4.2648970376958334e-05,
      "loss": 1.0099,
      "step": 58000
    },
    {
      "epoch": 4.008833021912689,
      "grad_norm": 1.019349455833435,
      "learning_rate": 3.991243073134022e-05,
      "loss": 0.986,
      "step": 59000
    },
    {
      "epoch": 4.0767793443179885,
      "grad_norm": 1.1023433208465576,
      "learning_rate": 3.7175891085722106e-05,
      "loss": 0.9036,
      "step": 60000
    }
  ],
  "logging_steps": 1000,
  "max_steps": 73585,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 10000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.1789318580505457e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
